import React, { useState, useEffect } from 'react';
import { View, Text, TouchableOpacity, StyleSheet, Alert, ActivityIndicator } from 'react-native';
import { Audio } from 'expo-av';
import * as Speech from 'expo-speech';
import AIModelService from '../services/AIModelService';

export default function AudioRecorder({ onTranscription }) {
  const [recording, setRecording] = useState(null);
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcribedText, setTranscribedText] = useState('');
  const [detectedLanguage, setDetectedLanguage] = useState('');
  const [permissionStatus, setPermissionStatus] = useState('checking');

  useEffect(() => {
    checkPermissions();
  }, []);

  useEffect(() => {
    return () => {
      if (recording && typeof recording.unloadAsync === 'function') {
        recording.unloadAsync().catch(console.error);
      }
    };
  }, [recording]);

  const checkPermissions = async () => {
    try {
      const { status } = await Audio.getPermissionsAsync();
      setPermissionStatus(status);
      console.log('í˜„ì¬ ë§ˆì´í¬ ê¶Œí•œ ìƒíƒœ:', status);
    } catch (error) {
      console.error('ê¶Œí•œ í™•ì¸ ì˜¤ë¥˜:', error);
      setPermissionStatus('undetermined');
    }
  };

  async function startRecording() {
    try {
      console.log('ë…¹ìŒ ì‹œì‘ ì‹œë„...');
      
      // ê¶Œí•œ ìš”ì²­
      const permission = await Audio.requestPermissionsAsync();
      console.log('ë§ˆì´í¬ ê¶Œí•œ ìƒíƒœ:', permission);
      
      if (permission.status !== 'granted') {
        setPermissionStatus(permission.status);
        Alert.alert(
          'ë§ˆì´í¬ ê¶Œí•œ í•„ìš”', 
          'ìŒì„± ì¸ì‹ì„ ìœ„í•´ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.\n\nì„¤ì • > ì•± > Expo Go > ê¶Œí•œì—ì„œ ë§ˆì´í¬ë¥¼ í—ˆìš©í•˜ì„¸ìš”.',
          [
            { text: 'ì·¨ì†Œ', style: 'cancel' },
            { text: 'ë‹¤ì‹œ ì‹œë„', onPress: () => checkPermissions() },
            { text: 'ì„¤ì •ìœ¼ë¡œ ì´ë™', onPress: () => {
              Alert.alert('ê¶Œí•œ ì„¤ì •', 'íœ´ëŒ€í° ì„¤ì •ì—ì„œ Expo Go ì•±ì˜ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
            }}
          ]
        );
        return;
      }

      setPermissionStatus('granted');

      console.log('ì˜¤ë””ì˜¤ ëª¨ë“œ ì„¤ì • ì¤‘...');
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
        shouldDuckAndroid: true,
        playThroughEarpieceAndroid: false,
        staysActiveInBackground: false,
      });

      console.log('ë…¹ìŒ ê°ì²´ ìƒì„± ì¤‘...');
      const recordingOptions = {
        ...Audio.RecordingOptionsPresets.HIGH_QUALITY,
        android: {
          extension: '.wav',
          outputFormat: Audio.RECORDING_OPTION_ANDROID_OUTPUT_FORMAT_DEFAULT,
          audioEncoder: Audio.RECORDING_OPTION_ANDROID_AUDIO_ENCODER_DEFAULT,
          sampleRate: 16000,
          numberOfChannels: 1,
          bitRate: 128000,
        },
        ios: {
          extension: '.wav',
          audioQuality: Audio.RECORDING_OPTION_IOS_AUDIO_QUALITY_HIGH,
          sampleRate: 16000,
          numberOfChannels: 1,
          bitRate: 128000,
          linearPCMBitDepth: 16,
          linearPCMIsBigEndian: false,
          linearPCMIsFloat: false,
        },
      };

      const { recording } = await Audio.Recording.createAsync(recordingOptions);
      console.log('ë…¹ìŒ ì‹œì‘ ì„±ê³µ');
      
      setRecording(recording);
      setIsRecording(true);
      setTranscribedText('');
      setDetectedLanguage('');
    } catch (err) {
      console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', err);
      Alert.alert(
        'ë…¹ìŒ ì˜¤ë¥˜', 
        `ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜: ${err.message}\n\në§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`
      );
    }
  }

  async function stopRecording() {
    try {
      setIsRecording(false);
      setIsProcessing(true);
      
      if (!recording) {
        setIsProcessing(false);
        Alert.alert('ì˜¤ë¥˜', 'ë…¹ìŒ ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        return;
      }

      await recording.stopAndUnloadAsync();
      const uri = recording.getURI();
      setRecording(undefined);
      
      // AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•´ì„œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
      const transcriptionResult = await AIModelService.transcribeAudio(uri);
      
      setTranscribedText(transcriptionResult.text);
      setDetectedLanguage(AIModelService.getLanguageName(transcriptionResult.language));
      setIsProcessing(false);
      
      onTranscription({
        text: transcriptionResult.text,
        language: transcriptionResult.language,
        confidence: transcriptionResult.confidence
      });
    } catch (error) {
      console.error('ìŒì„± ì¸ì‹ ì‹¤íŒ¨:', error);
      setIsProcessing(false);
      Alert.alert('ì˜¤ë¥˜', 'ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  }

  const speakText = (text) => {
    // ê°ì§€ëœ ì–¸ì–´ì— ë”°ë¼ TTS ì–¸ì–´ ì„¤ì •
    const languageCodeMap = {
      'í•œêµ­ì–´': 'ko-KR',
      'Tiáº¿ng Viá»‡t': 'vi-VN',
      'ç¹é«”ä¸­æ–‡': 'zh-TW',
      'English': 'en-US'
    };
    
    const ttsLanguage = languageCodeMap[detectedLanguage] || 'ko-KR';
    
    Speech.speak(text, {
      language: ttsLanguage,
      pitch: 1.0,
      rate: 0.8,
    });
  };

  // í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ìŒì„± ì¸ì‹ í•¨ìˆ˜
  const testVoiceRecognition = async () => {
    setIsProcessing(true);
    
    try {
      // AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•´ì„œ ë”ë¯¸ ìŒì„± ì¸ì‹ ì‹œë®¬ë ˆì´ì…˜
      const transcriptionResult = await AIModelService.transcribeAudio('test_audio');
      
      setTranscribedText(transcriptionResult.text);
      setDetectedLanguage(AIModelService.getLanguageName(transcriptionResult.language));
      setIsProcessing(false);
      
      onTranscription({
        text: transcriptionResult.text,
        language: transcriptionResult.language,
        confidence: transcriptionResult.confidence
      });
    } catch (error) {
      console.error('í…ŒìŠ¤íŠ¸ ìŒì„± ì¸ì‹ ì‹¤íŒ¨:', error);
      setIsProcessing(false);
      Alert.alert('ì˜¤ë¥˜', 'í…ŒìŠ¤íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  return (
    <View style={styles.container}>
      <View style={styles.statusContainer}>
        <Text style={styles.statusText}>
          {isRecording ? 'ğŸ¤ ë…¹ìŒ ì¤‘...' : 'ğŸµ ìŒì„± ì¸ì‹ ì¤€ë¹„'}
        </Text>
        {detectedLanguage && (
          <Text style={styles.languageText}>ê°ì§€ëœ ì–¸ì–´: {detectedLanguage}</Text>
        )}
        {permissionStatus !== 'granted' && (
          <View style={styles.permissionWarning}>
            <Text style={styles.permissionWarningText}>
              âš ï¸ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤
            </Text>
            <Text style={styles.permissionInstructionText}>
              ì„¤ì •ì—ì„œ Expo Go ì•±ì˜ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”
            </Text>
          </View>
        )}
      </View>

      <TouchableOpacity
        style={[
          styles.recordButton, 
          isRecording && styles.recording,
          isProcessing && styles.processing
        ]}
        onPress={isRecording ? stopRecording : startRecording}
        disabled={isProcessing || (permissionStatus !== 'granted' && !isRecording)}
      >
        {isProcessing ? (
          <View style={styles.processingContainer}>
            <ActivityIndicator color="white" size="small" />
            <Text style={[styles.buttonText, styles.processingText]}>ì²˜ë¦¬ ì¤‘...</Text>
          </View>
        ) : (
          <Text style={styles.buttonText}>
            {isRecording ? 'ğŸ›‘ ë…¹ìŒ ì¤‘ì§€' : 'ğŸ¤ ë…¹ìŒ ì‹œì‘'}
          </Text>
        )}
      </TouchableOpacity>

      {/* í…ŒìŠ¤íŠ¸ ë²„íŠ¼ (ë§ˆì´í¬ ê¶Œí•œì´ ì—†ì„ ë•Œ) */}
      {permissionStatus !== 'granted' && (
        <TouchableOpacity
          style={styles.testButton}
          onPress={testVoiceRecognition}
          disabled={isProcessing}
        >
          <Text style={styles.buttonText}>
            ğŸ§ª ìŒì„±ì¸ì‹ í…ŒìŠ¤íŠ¸ (ë”ë¯¸ ë°ì´í„°)
          </Text>
        </TouchableOpacity>
      )}
      
      {transcribedText ? (
        <View style={styles.transcriptionContainer}>
          <Text style={styles.transcriptionLabel}>ì¸ì‹ëœ ìŒì„±:</Text>
          <Text style={styles.transcriptionText}>{transcribedText}</Text>
          <View style={styles.actionButtons}>
            <TouchableOpacity
              style={styles.speakButton}
              onPress={() => speakText(transcribedText)}
            >
              <Text style={styles.buttonText}>ğŸ”Š ìŒì„± ì¬ìƒ</Text>
            </TouchableOpacity>
            <TouchableOpacity
              style={styles.translateButton}
              onPress={() => {
                // ì–¸ì–´ ì½”ë“œ ë§¤í•‘
                const languageCodeMap = {
                  'í•œêµ­ì–´': 'ko',
                  'Tiáº¿ng Viá»‡t': 'vi',
                  'ç¹é«”ä¸­æ–‡': 'zh-TW',
                  'English': 'en'
                };
                
                onTranscription({
                  text: transcribedText,
                  language: languageCodeMap[detectedLanguage] || 'ko',
                  shouldTranslate: true
                });
              }}
            >
              <Text style={styles.buttonText}>ğŸ”„ ë²ˆì—­í•˜ê¸°</Text>
            </TouchableOpacity>
          </View>
        </View>
      ) : null}
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    padding: 20,
    alignItems: 'center',
    flex: 1,
  },
  statusContainer: {
    alignItems: 'center',
    marginBottom: 30,
  },
  statusText: {
    fontSize: 18,
    fontWeight: '600',
    color: '#333',
    marginBottom: 5,
  },
  languageText: {
    fontSize: 14,
    color: '#666',
    fontStyle: 'italic',
  },
  recordButton: {
    backgroundColor: '#007AFF',
    paddingHorizontal: 40,
    paddingVertical: 20,
    borderRadius: 50,
    marginBottom: 30,
    minWidth: 200,
    alignItems: 'center',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.3,
    shadowRadius: 4,
    elevation: 5,
  },
  recording: {
    backgroundColor: '#FF3B30',
    transform: [{ scale: 1.05 }],
  },
  processing: {
    backgroundColor: '#FF9500',
  },
  processingContainer: {
    flexDirection: 'row',
    alignItems: 'center',
  },
  processingText: {
    marginLeft: 10,
  },
  buttonText: {
    color: 'white',
    fontSize: 18,
    fontWeight: 'bold',
  },
  transcriptionContainer: {
    backgroundColor: '#F2F2F7',
    padding: 20,
    borderRadius: 15,
    marginTop: 10,
    width: '100%',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 1 },
    shadowOpacity: 0.1,
    shadowRadius: 2,
    elevation: 2,
  },
  transcriptionLabel: {
    fontSize: 14,
    fontWeight: '600',
    color: '#666',
    marginBottom: 10,
  },
  transcriptionText: {
    fontSize: 16,
    marginBottom: 15,
    lineHeight: 24,
    color: '#333',
  },
  actionButtons: {
    flexDirection: 'row',
    justifyContent: 'space-between',
  },
  speakButton: {
    backgroundColor: '#34C759',
    paddingHorizontal: 20,
    paddingVertical: 12,
    borderRadius: 10,
    flex: 0.48,
    alignItems: 'center',
  },
  translateButton: {
    backgroundColor: '#FF9500',
    paddingHorizontal: 20,
    paddingVertical: 12,
    borderRadius: 10,
    flex: 0.48,
    alignItems: 'center',
  },
  permissionWarning: {
    backgroundColor: '#FFF3CD',
    padding: 15,
    borderRadius: 10,
    marginTop: 15,
    borderWidth: 1,
    borderColor: '#FFEAA7',
    alignItems: 'center',
  },
  permissionWarningText: {
    fontSize: 16,
    fontWeight: 'bold',
    color: '#856404',
    marginBottom: 5,
    textAlign: 'center',
  },
  permissionInstructionText: {
    fontSize: 14,
    color: '#856404',
    textAlign: 'center',
    lineHeight: 20,
  },
  testButton: {
    backgroundColor: '#28A745',
    paddingHorizontal: 30,
    paddingVertical: 15,
    borderRadius: 25,
    marginTop: 15,
    minWidth: 200,
    alignItems: 'center',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.2,
    shadowRadius: 4,
    elevation: 3,
  },
});